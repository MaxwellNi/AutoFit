# Block 3 Tasks Configuration
# All paths resolved via docs/audits/FULL_SCALE_POINTER.yaml
#
# CRITICAL UNIFIED PROTOCOL:
# 1. Early-K definition: K = number of SNAPSHOTS (rows), NOT days
# 2. Label time t0 = last snapshot in early-K window
# 3. All features must be available at t0 (leakage guard enforced)
# 4. Strict temporal splits: train_end < val_end < test_end (NO random)

# Global settings
pointer_path: docs/audits/FULL_SCALE_POINTER.yaml
output_base: runs/benchmarks
seed: 42
date_col: crawled_date_day
entity_col: entity_id

# Unified temporal split (shared across ALL tasks)
# CRITICAL: These dates are authoritative for reproducibility
split:
  method: temporal  # ONLY temporal allowed
  train_end: "2025-06-30"
  val_end: "2025-09-30"
  test_end: "2025-12-31"
  embargo_days: 7  # Gap between splits to prevent leakage

# Anti-leakage settings
anti_leakage:
  strict_temporal_split: true
  gap_days: 7  # Days between train and val/test
  verify_no_future_features: true
  fail_fast: true  # Raise RuntimeError on leakage

# Early-K configuration (CRITICAL: K = snapshots, NOT days)
early_k:
  description: "K is number of SNAPSHOTS per entity, not days"
  default_k: 30
  available_k: [7, 14, 30, 60, 90]

# Column mappings (legacy -> actual freeze columns)
column_mappings:
  total_amount_sold: funding_raised_usd
  success_binary: is_funded
  number_investors: investors_count
  total_offering_amount: funding_goal_usd

# Ablation configurations (shared across tasks)
ablations:
  core_only:
    use_text: false
    use_edgar: false
    description: "Core offering features only"
  core_text:
    use_text: true
    use_edgar: false
    description: "Core + text embeddings"
  core_edgar:
    use_text: false
    use_edgar: true
    description: "Core + EDGAR filing features"
  full:
    use_text: true
    use_edgar: true
    description: "All features: core + text + edgar"

# Task definitions
tasks:
  task1_outcome:
    description: "Outcome Prediction (classification + regression + ranking)"
    targets:
      - funding_raised_usd
      - investors_count
      - is_funded
    horizons: [7, 14, 30]  # task semantic horizon set; execution horizon is controlled by preset.horizons
    ablations:
      - core_only
      - core_text
      - core_edgar
      - full
    metrics:
      classification:
        - auc
        - prauc
        - logloss
        - brier
      regression:
        - mae
        - rmse
        - smape
      ranking:
        - ndcg@10
        - spearman

  task2_forecast:
    description: "Trajectory Forecasting (multi-horizon + quantiles)"
    targets:
      - funding_raised_usd
      - investors_count
    horizons: [1, 7, 14, 30]  # semantic horizon set; runner uses preset.horizons for comparable execution grid
    context_lengths: [30, 60, 90]  # Lookback in snapshots
    ablations:
      - core_only
      - core_text
      - core_edgar
      - full
    metrics:
      point:
        - mae
        - rmse
        - smape
        - mase
      quantile:
        - pinball_50
        - pinball_90
      probabilistic:
        - crps
        - interval_coverage_90

  task3_risk_adjust:
    description: "EDGAR-conditioned Risk Adjustment (OOD robustness)"
    targets:
      - funding_raised_usd
      - investors_count
    horizons: [30]  # K = early snapshot count
    ablations:
      - core_only
      - core_edgar
      - full
    ood_slices:
      size_shift:
        column: funding_goal_usd
        split_quantile: 0.5
        description: "Small vs large offerings"
      time_shift:
        column: crawled_date_day
        split_date: "2025-10-01"
        description: "Recent vs older"
      sector_shift:
        column: sector
        groups: ["Technology", "Real Estate", "Other"]
        description: "Industry sectors"
    metrics:
      - mae
      - rmse
      - degradation_pct
      - robustness_score
      - worst_slice_mae

# Presets for benchmarking
presets:
  smoke:
    description: "Minimal test run (< 2 min)"
    max_entities: 100
    max_rows: 1000
    horizons: [7]
    k_values: [7]
    models_per_category: 1
    n_bootstrap: 0
    
  quick:
    description: "Quick validation (< 10 min)"
    max_entities: 500
    max_rows: 10000
    horizons: [7, 14]
    k_values: [14, 30]
    models_per_category: 2
    n_bootstrap: 100
    
  standard:
    description: "Standard benchmark (< 1 hour per task)"
    max_entities: null
    max_rows: null
    horizons: [7, 14, 30]
    k_values: [7, 14, 30]
    models_per_category: null
    n_bootstrap: 500
    
  full:
    description: "Full benchmark for paper (several hours)"
    max_entities: null
    max_rows: null
    horizons: [1, 7, 14, 30]
    k_values: [7, 14, 30, 60, 90]
    models_per_category: null
    n_bootstrap: 1000

# AutoFit V7.1 controls
autofit_v71:
  enabled: true
  cv_scheme: "3x4_temporal"
  min_ensemble_size_heavy_tail: 2
  dynamic_weighting: true
  enable_regime_retrieval: true

# AutoFit V7.2 controls (evidence-driven rollout)
autofit_v72:
  enabled: true
  count_safe_mode: true
  count_two_part_head: true
  count_distribution_family: "auto"  # auto|poisson|tweedie|zinb
  champion_anchor: true
  offline_rl_policy: "offline_rule_v72"
  routing_key_schema: "lane_family+horizon_band+ablation+missingness_bucket"
  count_heads: ["poisson", "tweedie", "negbin"]
  binary_hazard_mode: "discrete_time_hazard"
  binary_calibration_mode: "auto"  # auto|platt|isotonic
  binary_metrics_gate_enabled: true
  anchor_policy: "champion_template_hard"
  coverage_controller: "missing_key_manifest_v1"
  retrieval_standardized: true
  execution_contract_required: true
  scheduler_memory_policy: "admission_guard_v1"
  sparse_moe_enabled: true
  sparse_moe_max_experts: 3
  sparse_moe_temperature: 0.45
  sparse_moe_min_weight: 0.05
  sparse_moe_blend_alpha: 0.20
  search_budget: 96

# Model categories for benchmarking
model_categories:
  statistical:
    - SeasonalNaive
    - AutoARIMA
    - ETS
    - Theta
    - MSTL

  ml_tabular:
    - LightGBM
    - XGBoost
    - CatBoost
    - RandomForest
    - HistGradientBoosting
    - Ridge
    - Lasso
    - ElasticNet

  deep_classical:
    - NBEATS
    - NHITS
    - TFT
    - DeepAR
    - LSTM
    - GRU

  transformer_sota:
    - PatchTST
    - iTransformer
    - TimeMixer
    - TimesNet
    - Autoformer
    - FEDformer
    - Informer

  foundation:
    - TimesFM
    - Chronos
    - Moirai
    - LagLlama

  irregular:
    - GRU_D
    - SAITS
    - NeuralCDE

# Training settings
training:
  max_epochs: 100
  patience: 10
  batch_size: 64
  learning_rate: 0.001
  weight_decay: 0.0001
