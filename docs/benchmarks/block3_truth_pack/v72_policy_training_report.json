{
  "generated_at_utc": "2026-02-24T00:57:58.374608+00:00",
  "policy_id": "offline_policy_v72_20260224_005758",
  "algorithm": "conservative_contextual_bandit",
  "deep_offline_rl_enabled": false,
  "dataset_path": "/mnt/aiongpfs/projects/eint/repo_root/docs/benchmarks/block3_truth_pack/v72_policy_dataset.csv",
  "n_dataset_rows": 104,
  "n_policy_states": 36,
  "state_policy": {
    "lane=heavy_tail|hb=short|ablation=core_edgar|miss=mid": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.978708,
      "confidence": 1.0,
      "n_samples": 6,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=mid|ablation=core_edgar|miss=mid": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.814721,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=long|ablation=core_edgar|miss=mid": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.697701,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=count|hb=short|ablation=core_edgar|miss=mid": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -194.450662,
      "confidence": 1.0,
      "n_samples": 6,
      "n_actions": 1
    },
    "lane=count|hb=mid|ablation=core_edgar|miss=mid": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -198.897348,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=count|hb=long|ablation=core_edgar|miss=mid": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -198.812839,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=binary|hb=short|ablation=core_edgar|miss=mid": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -171.04799,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=binary|hb=mid|ablation=core_edgar|miss=mid": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -171.218312,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=binary|hb=long|ablation=core_edgar|miss=mid": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -171.489301,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=short|ablation=core_only|miss=high": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.238447,
      "confidence": 1.0,
      "n_samples": 6,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=mid|ablation=core_only|miss=high": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.078219,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=long|ablation=core_only|miss=high": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -4.963918,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=count|hb=short|ablation=core_only|miss=high": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -510.481419,
      "confidence": 1.0,
      "n_samples": 6,
      "n_actions": 1
    },
    "lane=count|hb=mid|ablation=core_only|miss=high": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -511.04499,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=count|hb=long|ablation=core_only|miss=high": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -510.296884,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=binary|hb=short|ablation=core_only|miss=high": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -163.10135,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=binary|hb=mid|ablation=core_only|miss=high": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -163.375263,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=binary|hb=long|ablation=core_only|miss=high": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -163.294931,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=short|ablation=core_text|miss=mid": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.355986,
      "confidence": 1.0,
      "n_samples": 4,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=mid|ablation=core_text|miss=mid": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.19557,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=long|ablation=core_text|miss=mid": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -5.081157,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=count|hb=short|ablation=core_text|miss=mid": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -341.841238,
      "confidence": 1.0,
      "n_samples": 4,
      "n_actions": 1
    },
    "lane=count|hb=mid|ablation=core_text|miss=mid": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -341.63442,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=count|hb=long|ablation=core_text|miss=mid": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -342.371919,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=binary|hb=short|ablation=core_text|miss=mid": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -163.12409,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=binary|hb=mid|ablation=core_text|miss=mid": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -163.375263,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=binary|hb=long|ablation=core_text|miss=mid": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -163.294931,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=short|ablation=full|miss=low": {
      "template_id": "heavy_tail_deep_mix",
      "candidate_subset": "NHITS,PatchTST,NBEATS,Chronos",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -6.194695,
      "confidence": 1.0,
      "n_samples": 6,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=mid|ablation=full|miss=low": {
      "template_id": "heavy_tail_foundation_mix",
      "candidate_subset": "Chronos,Moirai,TimesFM,NHITS,PatchTST",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -6.134237,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=heavy_tail|hb=long|ablation=full|miss=low": {
      "template_id": "heavy_tail_foundation_mix",
      "candidate_subset": "Chronos,Moirai,TimesFM,NHITS,PatchTST",
      "count_family": "na",
      "binary_calibration_mode": "na",
      "top_k": "8",
      "reward_mean": -6.156043,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=count|hb=short|ablation=full|miss=low": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -181.258849,
      "confidence": 1.0,
      "n_samples": 6,
      "n_actions": 1
    },
    "lane=count|hb=mid|ablation=full|miss=low": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -181.270297,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=count|hb=long|ablation=full|miss=low": {
      "template_id": "count_nbeats_nhits_kan",
      "candidate_subset": "NBEATS,NHITS,KAN,LightGBMTweedie,XGBoostPoisson",
      "count_family": "auto",
      "binary_calibration_mode": "na",
      "top_k": "10",
      "reward_mean": -181.190791,
      "confidence": 1.0,
      "n_samples": 3,
      "n_actions": 1
    },
    "lane=binary|hb=short|ablation=full|miss=low": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -171.04799,
      "confidence": 1.0,
      "n_samples": 2,
      "n_actions": 1
    },
    "lane=binary|hb=mid|ablation=full|miss=low": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -171.218312,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    },
    "lane=binary|hb=long|ablation=full|miss=low": {
      "template_id": "binary_patchtst_nhits",
      "candidate_subset": "PatchTST,NHITS,TimeMixer,iTransformer",
      "count_family": "na",
      "binary_calibration_mode": "auto",
      "top_k": "8",
      "reward_mean": -171.489301,
      "confidence": 1.0,
      "n_samples": 1,
      "n_actions": 1
    }
  },
  "notes": [
    "Selection uses strict historical evidence only.",
    "No test-set feedback used during policy construction.",
    "Deep offline RL path is feature-gated and disabled by default."
  ]
}