# Wide Freeze Design

## Pipeline Data Products
1. **Wide Snapshot (Step 3)**
   - Source: `data/raw/offers` (Delta)
   - Output: `runs/offers_core_full_snapshot_wide_${STAMP}/offers_core_snapshot.parquet`
   - Nested columns route to extras as:
     - `<col>__json`, `<col>__len`, `<col>__hash`

2. **Wide Daily (Step 4)**
   - Source: wide snapshot
   - Output: `runs/offers_core_full_daily_wide_${STAMP}/offers_core_daily.parquet`
   - Aggregation: last-non-null by `entity_id` and day
   - Derived columns include delta and pct change

3. **Snapshots Index (Step 5)**
   - `snapshots_offer_day.parquet`
   - `snapshots_cik_day.parquet`

4. **EDGAR Store (Step 6)**
   - Output: `runs/edgar_feature_store_full_daily_wide_${STAMP}/edgar_features/**`
   - EDGAR aligned to snapshot day and cik

5. **Multiscale Views (Step 7)**
   - Output: `runs/multiscale_full_wide_${STAMP}/`

6. **Audits + Freeze Selection (Steps 8-10)**
   - `column_manifest.{json,md}`
   - `raw_cardinality_coverage_wide_${STAMP}.{json,md}`
   - `freeze_candidates.{json,md}`
   - updated `docs/audits/FULL_SCALE_POINTER.yaml`

---

## Block 3 Architecture (WIDE2 Freeze Seal Complete)

### Data Layout
```
docs/audits/FULL_SCALE_POINTER.yaml
        │
        ▼ (resolved by FreezePointer)
        │
        ├─> offers_core_daily: ${pointer.offers_core_daily.dir}/offers_core_daily.parquet
        ├─> offers_text:       ${pointer.offers_text.dir}/offers_text.parquet
        └─> edgar_store:       ${pointer.edgar_store_full_daily.dir}/edgar_features/**

Note: All paths are resolved dynamically via FreezePointer.
      No hard-coded stamp paths in production code.
```

### Join Keys
| Left Table      | Right Table  | Keys                              |
|-----------------|--------------|-----------------------------------|
| offers_core     | offers_text  | `entity_id` + `crawled_date_day`  |
| offers_core     | edgar_store  | `cik` + `crawled_date_day`        |

### Block3Dataset Interface
```python
from src.narrative.data_preprocessing.block3_dataset import Block3Dataset

ds = Block3Dataset.from_pointer()  # Loads from FULL_SCALE_POINTER.yaml
ds.run_consistency_checks()        # Verify referential integrity

core_df = ds.get_offers_core_daily()
text_df = ds.get_offers_text()
edgar_df = ds.get_edgar_store()

# Explicit joins
core_text = ds.join_core_with_text(core_df, text_df)
core_edgar = ds.join_core_with_edgar(core_df, edgar_df)
```

### Benchmark Pipeline
```
Block3Dataset
        │
        ▼
BenchmarkHarness (scripts/run_block3_benchmark.py)
        │
        ├─> Ablation: core_only, core+text, core+edgar, full
        │
        ├─> Train/Val/Test split by time (walk-forward or temporal)
        │
        └─> Model Categories:
                ├─> Statistical:       SeasonalNaive, ETS, AutoARIMA
                ├─> ML Tabular:        LightGBM, XGBoost, CatBoost
                ├─> Deep Classical:    N-BEATS, TFT, DeepAR
                ├─> Transformer SOTA:  PatchTST, iTransformer, TimeMixer
                ├─> GluonTS:           DeepAR, WaveNet
                └─> Foundation:        TimesFM, Chronos, Moirai
```

### AutoFit Meta-Features
Generated by `scripts/block3_profile_data.py`:

| Meta-Feature          | Computation                                | Range |
|-----------------------|--------------------------------------------|-------|
| `nonstationarity_score` | 1 - mean(p-values) from ADF test         | 0-1   |
| `periodicity_score`   | Max ACF in [6,14] lag range                | 0-1   |
| `multiscale_score`    | Ratio of slow/fast wavelet energy          | 0-1   |
| `long_memory_score`   | Hurst exponent estimate                    | 0-1   |
| `irregular_score`     | std(time_gap) / mean(time_gap)             | 0+    |
| `heavy_tail_score`    | Fraction where kurtosis > 3                | 0-1   |
| `exog_strength`       | Mean R² of target ~ exog features          | 0-1   |
| `edgar_strength`      | R² with EDGAR features                     | 0-1   |
| `text_strength`       | R² with text features                      | 0-1   |
| `missing_rate`        | Overall missing value fraction             | 0-1   |

### AutoFit Composer
Location: `src/narrative/auto_fit/rule_based_composer.py`

Decision Tree:
```
if multiscale_score > 0.7:
    backbone = TimeMixer      # Multi-resolution
elif periodicity_score > 0.6:
    backbone = PatchTST       # Strong periodicity
elif nonstationarity_score < 0.3:
    backbone = iTransformer   # Stationary
else:
    backbone = TimesNet       # General purpose

if exog_strength > 0.3:
    fusion = cross_attention  # Strong exogenous
elif text_strength > 0.2 or edgar_strength > 0.2:
    fusion = FiLM             # Moderate auxiliary
else:
    fusion = none             # Endogenous only

if heavy_tail_score > 0.3:
    loss = Huber              # Outlier robust
else:
    loss = MSE                # Standard
```

### Concept Bottleneck
Location: `src/narrative/explainability/concept_bottleneck.py`

Concept Categories:
- **Risk**: financial_risk, market_risk, operational_risk
- **Sentiment**: optimism, pessimism, uncertainty
- **Disclosure**: transparency, regulatory_compliance
- **Financial**: funding_progress, investor_interest

Usage:
```python
from src.narrative.explainability.concept_bottleneck import ConceptBottleneck

cb = ConceptBottleneck()
cb.fit(df, target_col, text_cols, edgar_cols)
output = cb.predict(text_features, edgar_features)
print(cb.explain(output))
```

---

## Runtime Topologies

### Topology A: Cluster SLURM (iris/aion)
- Full: `scripts/slurm/run_wide_freeze_aion.sbatch`
- Resume: `scripts/slurm/run_wide_freeze_aion_from_daily.sbatch`
- Monitor: `scripts/slurm/monitor_wide_freeze_aion.sbatch` + `scripts/monitor_wide_freeze_resume.sh`

### Topology B: 4090 Local (no SLURM)
- Full: `scripts/ssh_4090/run_wide_freeze_aion_4090.sh`
- Resume: `scripts/ssh_4090/run_wide_freeze_aion_from_daily_4090.sh`
- Local monitor: `scripts/ssh_4090/monitor_wide_freeze_aion_4090.sh`

## Hardening Added During This Thread
- Daily builder now supports DuckDB runtime controls via env:
  - `DUCKDB_MEMORY_LIMIT_GB`
  - `DUCKDB_THREADS`
- Sbatch wrappers detect explicit bash path via `BASH_BIN` fallback chain.
- Resume sbatch preflights and auto-installs `duckdb` and `deltalake` when missing.
- Full/Resume wrappers export OpenMP/BLAS thread limits for reproducibility.

## Data Mobility Design (Implemented)
- Cluster -> Mac pull:
  - `scripts/pull_outputs_from_cluster.sh`
  - defaults set for ULHPC access: `access-iris.uni.lu:8022`
- Mac -> 4090 push:
  - `scripts/sync_outputs_to_4090.sh`
- Optional Cluster -> Mac push:
  - `scripts/sync_outputs_to_mac.sh`
- Required synced sets:
  - `runs/offers_core_full_snapshot_wide_${STAMP}`
  - `runs/offers_core_full_daily_wide_${STAMP}` (if exists)
  - `runs/edgar_feature_store_full_daily_wide_${STAMP}` (if exists)
  - `runs/multiscale_full_wide_${STAMP}` (if exists)
  - `runs/orchestrator/20260129_073037/analysis/wide_${STAMP}`
  - `runs/selections/b11_v2_canonical`
  - `runs/offers_text_v1_20260129_073037_full` (if referenced)
  - `configs/column_contract_wide.yaml`
  - `docs/audits/*`

## Failure Modes and Applied Fixes
1. Step 4 OOM (observed in job `11029034`)
   - Fix: move daily build to DuckDB backend and export memory/thread limits.
2. `bash` missing within `srun` (observed in job `11029184`)
   - Fix: `BASH_BIN` detection and explicit executable path in sbatch.
3. Invalid CPU shape at submit time
   - Fix: `--ntasks-per-node=1`, `-c 16`.
4. Queue stagnation due priority + whole-node requests
   - Parallel submission strategy added (`mem=64G` variant).

## Manifest and Audit Requirements
Every product directory must include `MANIFEST.json` with:
- source version metadata
- rows scanned/emitted
- cmd args and git hash
- schema/output columns
- grain and partition strategy

Audit PASS gates:
- `column_manifest.json`: contract integrity and EDGAR recompute checks
- `raw_cardinality_coverage_wide_${STAMP}.json`: full-scan coverage integrity
- pointer update in `docs/audits/FULL_SCALE_POINTER.yaml`

## Single Source of Truth
`docs/audits/FULL_SCALE_POINTER.yaml` remains the only approved Block 3 input pointer.
